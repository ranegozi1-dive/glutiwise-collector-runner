name: GlutiWise Collector (SAFE seed + prices, ONE FLOW)

on:
  workflow_dispatch:
    inputs:
      run_mode:
        description: "inspect | seed_products | stores_prices"
        required: true
        default: "inspect"
      send_to_make:
        description: "רק עבור stores_prices: לשלוח ל-Make (true/false)"
        required: true
        default: "false"
      limit_seed:
        description: "LIMIT להרצת seed (מומלץ 20)"
        required: true
        default: "20"
      limit_prices:
        description: "LIMIT להרצת מחירים (מומלץ 120)"
        required: true
        default: "120"
      seed_limit:
        description: "כמה ברקודים להוציא ל-products_seed.csv (מומלץ 2000)"
        required: true
        default: "2000"
      max_records:
        description: "תקרת records ל-payload.json (מומלץ 3000)"
        required: true
        default: "3000"

jobs:
  run:
    runs-on: ubuntu-latest
    steps:
      - name: Prepare folders
        run: |
          mkdir -p dumps out

      - name: Pull scraper image
        run: |
          docker pull erlichsefi/israeli-supermarket-scarpers:latest

      # =========================
      # INSPECT (no Make)
      # =========================
      - name: Inspect image (fast)
        if: ${{ inputs.run_mode == 'inspect' }}
        run: |
          set -e
          docker run --rm --entrypoint sh erlichsefi/israeli-supermarket-scarpers:latest -lc '
            set -e
            echo "== HINTS (grep) =="
            grep -RIn --line-number --binary-files=without-match -E "ENABLED_FILE_TYPES|STORE_FILE|PRICE|PROMO|FULL|FILE_TYPE" . 2>/dev/null | head -n 200 || true
            echo "== DONE =="
          '

      # =========================
      # DISCOVER PRICE TYPES (SAFE)
      # =========================
      - name: Discover PRICE file types (SAFE - correct import, never empty)
        if: ${{ inputs.run_mode != 'inspect' }}
        id: discover
        run: |
          set -euo pipefail

          docker run --rm --entrypoint python3 erlichsefi/israeli-supermarket-scarpers:latest - <<'PY' > price_types.txt
          from il_supermarket_scarper.utils.file_types import FileTypesFilters
          print(",".join(FileTypesFilters.only_price()))
          PY

          PRICE_TYPES="$(cat price_types.txt | tr -d '\r\n' | sed 's/,,*/,/g; s/^,//; s/,$//')"
          echo "Discovered PRICE types: $PRICE_TYPES"
          [ -z "$PRICE_TYPES" ] && echo "ERROR:EMPTY_PRICE_TYPES" && exit 2
          echo "price_types=$PRICE_TYPES" >> "$GITHUB_OUTPUT"

      # =========================
      # DOWNLOAD STORE+PRICE (seed_products / stores_prices)
      # =========================
      - name: Download STORE + PRICE files
        if: ${{ inputs.run_mode == 'seed_products' || inputs.run_mode == 'stores_prices' }}
        run: |
          set -euo pipefail

          PRICE_TYPES="${{ steps.discover.outputs.price_types }}"
          ENABLED_FILE_TYPES="STORE_FILE,$PRICE_TYPES"
          ENABLED_FILE_TYPES="$(echo "$ENABLED_FILE_TYPES" | sed 's/,,*/,/g; s/^,//; s/,$//')"
          echo "$ENABLED_FILE_TYPES" | grep -q ",," && echo "ERROR:EMPTY_TOKEN_IN_ENABLED_FILE_TYPES" && exit 2

          if [ "${{ inputs.run_mode }}" = "seed_products" ]; then
            LIMIT="${{ inputs.limit_seed }}"
          else
            LIMIT="${{ inputs.limit_prices }}"
          fi

          echo "ENABLED_FILE_TYPES=$ENABLED_FILE_TYPES"
          echo "LIMIT=$LIMIT"

          docker run --rm \
            -v "${{ github.workspace }}/dumps:/usr/src/app/dumps" \
            -e ENABLED_SCRAPERS="RAMI_LEVY,SHUFERSAL,YOHANANOF" \
            -e ENABLED_FILE_TYPES="$ENABLED_FILE_TYPES" \
            -e LIMIT="$LIMIT" \
            erlichsefi/israeli-supermarket-scarpers:latest

      # =========================
      # SEED: products_seed.csv (PRICE-only, no STORE dependency)
      # =========================
      - name: Build products_seed.csv (PRICE-only)
        if: ${{ inputs.run_mode == 'seed_products' }}
        env:
          SEED_LIMIT: ${{ inputs.seed_limit }}
        run: |
          set -euo pipefail
          python3 - <<'PY'
          import os, re, glob, gzip, zipfile
          import xml.etree.ElementTree as ET

          SEED_LIMIT=int(os.environ.get("SEED_LIMIT","2000"))

          def localname(tag): return tag.split("}")[-1] if "}" in tag else tag
          def norm(s): return re.sub(r"\s+"," ",(s or "").strip())

          def load_xml_roots(path):
              lp=path.lower()
              if lp.endswith(".zip"):
                  roots=[]
                  with zipfile.ZipFile(path,"r") as z:
                      for nm in z.namelist():
                          if nm.lower().endswith(".xml"):
                              roots.append(ET.fromstring(z.read(nm)))
                  return roots
              if lp.endswith(".xml.gz") or lp.endswith(".gz"):
                  with gzip.open(path,"rb") as f:
                      return [ET.fromstring(f.read())]
              return [ET.parse(path).getroot()]

          def iter_dump_paths():
              for p in glob.glob("dumps/**/*", recursive=True):
                  if os.path.isfile(p) and p.lower().endswith((".xml",".gz",".zip",".xml.gz")):
                      yield p

          BARCODE_KEYS = {"itemcode","barcode","gtin","ean","code","itemid","itemnumber"}
          NAME_KEYS = {"itemname","itemdescription","productname","description","name"}

          def extract_any(elem, keys):
              keys={k.lower() for k in keys}
              for el in elem.iter():
                  if localname(el.tag).lower() in keys and (el.text or "").strip():
                      return norm(el.text)
              for el in elem.iter():
                  for k,v in (el.attrib or {}).items():
                      kk=str(k).lower()
                      if any(x in kk for x in ["barcode","gtin","itemcode","ean","code"]):
                          vv=(v or "").strip()
                          if vv: return norm(vv)
              return ""

          seed={}
          stats={"files_seen":0,"roots_seen":0,"items_seen":0}

          for path in iter_dump_paths():
              base=os.path.basename(path).lower()
              if base.startswith("stores"):
                  continue
              stats["files_seen"] += 1
              try:
                  roots=load_xml_roots(path)
              except Exception:
                  continue
              for root in roots:
                  stats["roots_seen"] += 1
                  for node in root.iter():
                      if localname(node.tag).lower() not in {"item","product"}:
                          continue
                      stats["items_seen"] += 1
                      bc=extract_any(node, BARCODE_KEYS).strip()
                      if not bc:
                          continue
                      if bc not in seed and len(seed) < SEED_LIMIT:
                          nm=extract_any(node, NAME_KEYS).strip()
                          seed[bc]=nm
                      if len(seed) >= SEED_LIMIT:
                          break
                  if len(seed) >= SEED_LIMIT:
                      break
              if len(seed) >= SEED_LIMIT:
                  break

          os.makedirs("out", exist_ok=True)
          with open("out/products_seed.csv","w",encoding="utf-8") as f:
              f.write("barcode,name\n")
              for bc,nm in seed.items():
                  f.write(f"{bc},{(nm or '').replace(',', ' ')}\n")

          with open("out/seed_stats.txt","w",encoding="utf-8") as f:
              for k,v in stats.items():
                  f.write(f"{k}: {v}\n")
              f.write(f"seed_unique: {len(seed)}\n")

          print(f"seed_unique={len(seed)}")
          PY

      # =========================
      # STORES_PRICES: records-only payload (bounded + dedupe)
      # Also writes products_seed.csv again (same seed_map) so import matches payload.
      # =========================
      - name: Build prices payload (records-only, bounded, self-seeded)
        if: ${{ inputs.run_mode == 'stores_prices' }}
        env:
          SEED_LIMIT: ${{ inputs.seed_limit }}
          MAX_RECORDS: ${{ inputs.max_records }}
        run: |
          set -euo pipefail
          python3 - <<'PY'
          import os, re, json, glob, gzip, zipfile
          import xml.etree.ElementTree as ET
          from datetime import datetime, timezone

          SEED_LIMIT = int(os.environ.get("SEED_LIMIT","2000"))
          MAX_RECORDS_TOTAL = int(os.environ.get("MAX_RECORDS","3000"))

          def now_z():
              return datetime.now(timezone.utc).replace(microsecond=0).isoformat().replace("+00:00","Z")
          def localname(tag): return tag.split("}")[-1] if "}" in tag else tag
          def norm(s): return re.sub(r"\s+"," ",(s or "").strip())

          def load_xml_roots(path):
              lp=path.lower()
              if lp.endswith(".zip"):
                  roots=[]
                  with zipfile.ZipFile(path,"r") as z:
                      for nm in z.namelist():
                          if nm.lower().endswith(".xml"):
                              roots.append(ET.fromstring(z.read(nm)))
                  return roots
              if lp.endswith(".xml.gz") or lp.endswith(".gz"):
                  with gzip.open(path,"rb") as f:
                      return [ET.fromstring(f.read())]
              return [ET.parse(path).getroot()]

          def iter_dump_paths():
              for p in glob.glob("dumps/**/*", recursive=True):
                  if os.path.isfile(p) and p.lower().endswith((".xml",".gz",".zip",".xml.gz")):
                      yield p

          BARCODE_KEYS={"itemcode","barcode","gtin","ean","code","itemid","itemnumber"}
          NAME_KEYS={"itemname","itemdescription","productname","description","name"}
          PRICE_KEYS={"itemprice","price","unitprice","saleprice","priceafterdiscount","priceinclvat"}

          def extract_any(elem, keys):
              keys={k.lower() for k in keys}
              for el in elem.iter():
                  if localname(el.tag).lower() in keys and (el.text or "").strip():
                      return norm(el.text)
              for el in elem.iter():
                  for k,v in (el.attrib or {}).items():
                      kk=str(k).lower()
                      if any(x in kk for x in ["barcode","gtin","itemcode","ean","code"]):
                          vv=(v or "").strip()
                          if vv: return norm(vv)
              return ""

          def safe_float(x):
              x=(x or "").strip().replace(",", ".")
              try:
                  v=float(x)
                  return v if v>=0 else None
              except Exception:
                  return None

          CHAINID_TO_RETAILER={"7290027600007":"ramilevy","7290058140886":"shufersal"}
          def retailer_from(chain_id, chain_name):
              if chain_id in CHAINID_TO_RETAILER: return CHAINID_TO_RETAILER[chain_id]
              cn=chain_name or ""
              if "שופרסל" in cn: return "shufersal"
              if "רמי" in cn: return "ramilevy"
              if "יוחננוף" in cn or "YOHANANOF" in cn.upper(): return "yohananof"
              return None

          stats = {"price_files_seen":0,"price_candidates_parsed":0,"items_scanned":0,"seed_unique":0,"records_after_dedupe":0}

          # 1) seed_map (bounded)
          seed_map={}
          for path in iter_dump_paths():
              base=os.path.basename(path).lower()
              if base.startswith("stores"): 
                  continue
              stats["price_files_seen"] += 1
              try:
                  roots=load_xml_roots(path)
              except Exception:
                  continue
              for root in roots:
                  chain_id=extract_any(root, {"chainid"})
                  chain_name=extract_any(root, {"chainname"})
                  store_id=extract_any(root, {"storeid"})
                  retailer=retailer_from(chain_id, chain_name)
                  if not retailer or not store_id:
                      continue
                  stats["price_candidates_parsed"] += 1

                  for node in root.iter():
                      if localname(node.tag).lower() not in {"item","product"}:
                          continue
                      stats["items_scanned"] += 1
                      bc=extract_any(node, BARCODE_KEYS).strip()
                      if not bc:
                          continue
                      if bc not in seed_map and len(seed_map) < SEED_LIMIT:
                          nm=extract_any(node, NAME_KEYS).strip()
                          seed_map[bc]=nm
                          stats["seed_unique"]=len(seed_map)
                      if len(seed_map) >= SEED_LIMIT:
                          break
                  if len(seed_map) >= SEED_LIMIT:
                      break
              if len(seed_map) >= SEED_LIMIT:
                  break

          # 2) records only for seed_map (bounded + dedupe by price_key)
          dedup={}
          for path in iter_dump_paths():
              base=os.path.basename(path).lower()
              if base.startswith("stores"): 
                  continue
              try:
                  roots=load_xml_roots(path)
              except Exception:
                  continue
              for root in roots:
                  chain_id=extract_any(root, {"chainid"})
                  chain_name=extract_any(root, {"chainname"})
                  store_id=extract_any(root, {"storeid"})
                  retailer=retailer_from(chain_id, chain_name)
                  if not retailer or not store_id:
                      continue
                  store_key=f"{retailer}:{store_id}"
                  updated_at=now_z()

                  for node in root.iter():
                      if localname(node.tag).lower() not in {"item","product"}:
                          continue
                      bc=extract_any(node, BARCODE_KEYS).strip()
                      if not bc or bc not in seed_map:
                          continue
                      pv=safe_float(extract_any(node, PRICE_KEYS))
                      if pv is None:
                          continue
                      price_key=f"{bc}:{store_key}"
                      dedup[price_key]={
                          "price_key":price_key,
                          "barcode":bc,
                          "store_key":store_key,
                          "price":pv,
                          "updated_at":updated_at
                      }
                      if len(dedup) >= MAX_RECORDS_TOTAL:
                          break
                  if len(dedup) >= MAX_RECORDS_TOTAL:
                      break
              if len(dedup) >= MAX_RECORDS_TOTAL:
                  break

          records=list(dedup.values())
          stats["records_after_dedupe"]=len(records)

          os.makedirs("out", exist_ok=True)

          # Always write products_seed.csv matching the exact barcodes used to build records
          with open("out/products_seed.csv","w",encoding="utf-8") as f:
              f.write("barcode,name\n")
              for bc,nm in seed_map.items():
                  f.write(f"{bc},{(nm or '').replace(',', ' ')}\n")

          payload={
              "source":"collector_prices_records_only_bounded",
              "generated_at":now_z(),
              "records":records
          }
          with open("out/payload.json","w",encoding="utf-8") as f:
              json.dump(payload,f,ensure_ascii=False)

          with open("out/price_stats.txt","w",encoding="utf-8") as f:
              for k,v in stats.items():
                  f.write(f"{k}: {v}\n")

          print(f"seed_unique={stats['seed_unique']}, records_after_dedupe={stats['records_after_dedupe']}")
          PY

      - name: Upload artifacts (out/)
        if: ${{ inputs.run_mode != 'inspect' }}
        uses: actions/upload-artifact@v4
        with:
          name: glutiwise-out
          path: out/

      # =========================
      # POST TO MAKE (ONE POST)
      # =========================
      - name: POST out/payload.json to Make (ONE POST)
        if: ${{ inputs.run_mode == 'stores_prices' && inputs.send_to_make == 'true' }}
        env:
          MAKE_WEBHOOK_URL: ${{ secrets.MAKE_WEBHOOK_URL }}
          MAKE_APIKEY: ${{ secrets.MAKE_APIKEY }}
        run: |
          set -euo pipefail
          test -f out/payload.json
          # Safety: avoid burning Make if records are empty
          python3 - <<'PY'
          import json
          p=json.load(open("out/payload.json","r",encoding="utf-8"))
          n=len(p.get("records") or [])
          print(f"records={n}")
          if n < 2:
              raise SystemExit("ABORT: records<2 (not sending to Make)")
          PY
          curl -sS -X POST "$MAKE_WEBHOOK_URL" \
            -H "Content-Type: application/json" \
            -H "x-make-apikey: $MAKE_APIKEY" \
            --data-binary @out/payload.json
