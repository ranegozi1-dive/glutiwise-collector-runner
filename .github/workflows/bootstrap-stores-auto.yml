name: GlutiWise Collector (Route A + pre-upsert products)

on:
  workflow_dispatch:
    inputs:
      run_mode:
        description: "inspect | seed_products | stores_prices"
        required: true
        default: "stores_prices"
      send_to_make:
        description: "לשלוח ל-Make (true/false)"
        required: true
        default: "true"
      limit_prices:
        description: "LIMIT למחירים (20 לבדיקה, 120 להרצה מלאה)"
        required: true
        default: "20"
      max_records:
        description: "תקרת records ל-payload.json"
        required: true
        default: "3000"
      max_stores:
        description: "תקרת stores ל-payload.json (MVP=30)"
        required: true
        default: "30"

jobs:
  run:
    runs-on: ubuntu-latest
    steps:
      - name: Prepare folders
        run: |
          mkdir -p dumps out

      - name: Pull scraper image
        run: |
          docker pull erlichsefi/israeli-supermarket-scarpers:latest

      - name: Inspect image (fast hints)
        if: ${{ inputs.run_mode == 'inspect' }}
        run: |
          set -euo pipefail
          docker run --rm --entrypoint sh erlichsefi/israeli-supermarket-scarpers:latest -lc '
            set -e
            grep -RIn --line-number --binary-files=without-match -E "ENABLED_FILE_TYPES|STORE_FILE|PRICE_FILE|PRICE_FULL_FILE|FILE_TYPE" . 2>/dev/null | head -n 200 || true
          '

      - name: Download STORE + PRICE files (hardcoded types)
        if: ${{ inputs.run_mode == 'stores_prices' }}
        run: |
          set -euo pipefail
          ENABLED_FILE_TYPES="STORE_FILE,PRICE_FILE,PRICE_FULL_FILE"
          LIMIT="${{ inputs.limit_prices }}"
          echo "ENABLED_FILE_TYPES=$ENABLED_FILE_TYPES"
          echo "LIMIT=$LIMIT"
          docker run --rm \
            -v "${{ github.workspace }}/dumps:/usr/src/app/dumps" \
            -e ENABLED_SCRAPERS="RAMI_LEVY,SHUFERSAL,YOHANANOF" \
            -e ENABLED_FILE_TYPES="$ENABLED_FILE_TYPES" \
            -e LIMIT="$LIMIT" \
            erlichsefi/israeli-supermarket-scarpers:latest

      - name: Build payload (stores+records) + products_upsert
        if: ${{ inputs.run_mode == 'stores_prices' }}
        env:
          MAX_RECORDS: ${{ inputs.max_records }}
          MAX_STORES: ${{ inputs.max_stores }}
        run: |
          set -euo pipefail
          python3 - <<'PY'
          import os, re, json, glob, gzip, zipfile
          import xml.etree.ElementTree as ET
          from datetime import datetime, timezone

          MAX_RECORDS_TOTAL = int(os.environ.get("MAX_RECORDS","3000"))
          MAX_STORES_TOTAL  = int(os.environ.get("MAX_STORES","30"))

          def now_z():
              return datetime.now(timezone.utc).replace(microsecond=0).isoformat().replace("+00:00","Z")
          def localname(tag): return tag.split("}")[-1] if "}" in tag else tag
          def norm(s): return re.sub(r"\s+"," ",(s or "").strip())
          def canon_store_id(s: str) -> str:
              s=(s or "").strip()
              if re.fullmatch(r"\d+", s or ""):
                  try: return str(int(s))
                  except: return s
              return s

          def load_xml_roots(path):
              lp=path.lower()
              if lp.endswith(".zip"):
                  roots=[]
                  with zipfile.ZipFile(path,"r") as z:
                      for nm in z.namelist():
                          if nm.lower().endswith(".xml"):
                              roots.append(ET.fromstring(z.read(nm)))
                  return roots
              if lp.endswith(".xml.gz") or lp.endswith(".gz"):
                  with gzip.open(path,"rb") as f:
                      return [ET.fromstring(f.read())]
              return [ET.parse(path).getroot()]

          def iter_dump_paths():
              for p in glob.glob("dumps/**/*", recursive=True):
                  if os.path.isfile(p) and p.lower().endswith((".xml",".gz",".zip",".xml.gz")):
                      yield p

          def extract_any(elem, keys):
              keys={k.lower() for k in keys}
              for el in elem.iter():
                  if localname(el.tag).lower() in keys and (el.text or "").strip():
                      return norm(el.text)
              return ""

          BARCODE_KEYS={"itemcode","barcode","gtin","ean","code","itemid","itemnumber"}
          NAME_KEYS={"itemname","itemdescription","productname","description","name"}
          PRICE_KEYS={"itemprice","price","unitprice","saleprice","priceafterdiscount","priceinclvat"}

          def extract_barcode(node):
              bc = extract_any(node, BARCODE_KEYS).strip()
              if bc: return bc
              for el in node.iter():
                  for k,v in (el.attrib or {}).items():
                      kk=str(k).lower()
                      if any(x in kk for x in ["barcode","gtin","itemcode","ean","code"]):
                          vv=(v or "").strip()
                          if vv: return norm(vv)
              return ""

          def safe_float(x):
              x=(x or "").strip().replace(",", ".")
              try:
                  v=float(x)
                  return v if v>=0 else None
              except:
                  return None

          CHAINID_TO_RETAILER={"7290027600007":"ramilevy","7290058140886":"shufersal"}
          def retailer_from(chain_id, chain_name):
              if (chain_id or "") in CHAINID_TO_RETAILER: return CHAINID_TO_RETAILER[chain_id]
              cn=chain_name or ""
              if "שופרסל" in cn: return "shufersal"
              if "רמי" in cn: return "ramilevy"
              if "יוחננוף" in cn or "YOHANANOF" in cn.upper(): return "yohananof"
              return None

          dedup={}
          barcode_to_name={}
          store_keys_seen=[]

          for path in iter_dump_paths():
              base=os.path.basename(path).lower()
              if base.startswith("stores"):
                  continue
              try:
                  roots=load_xml_roots(path)
              except:
                  continue

              for root in roots:
                  chain_id=extract_any(root, {"chainid"})
                  chain_name=extract_any(root, {"chainname"})
                  store_id=canon_store_id(extract_any(root, {"storeid"}))
                  retailer=retailer_from(chain_id, chain_name)
                  if not retailer or not store_id:
                      continue

                  store_key=f"{retailer}:{store_id}"
                  store_keys_seen.append(store_key)

                  updated_at=now_z()
                  for node in root.iter():
                      if localname(node.tag).lower() not in {"item","product"}:
                          continue
                      bc=extract_barcode(node)
                      if not bc:
                          continue
                      nm=extract_any(node, NAME_KEYS).strip()
                      if bc not in barcode_to_name and nm:
                          barcode_to_name[bc]=nm

                      pv=safe_float(extract_any(node, PRICE_KEYS))
                      if pv is None:
                          continue

                      price_key=f"{bc}:{store_key}"
                      dedup[price_key]={
                          "price_key": price_key,
                          "barcode": bc,
                          "store_key": store_key,
                          "price": pv,
                          "updated_at": updated_at
                      }
                      if len(dedup) >= MAX_RECORDS_TOTAL:
                          break
                  if len(dedup) >= MAX_RECORDS_TOTAL:
                      break
              if len(dedup) >= MAX_RECORDS_TOTAL:
                  break

          records=list(dedup.values())

          # select up to MAX_STORES_TOTAL store_keys from records (guaranteed coverage)
          uniq=[]
          seen=set()
          for r in records:
              sk=r["store_key"]
              if sk not in seen:
                  seen.add(sk); uniq.append(sk)
              if len(uniq) >= MAX_STORES_TOTAL:
                  break

          # filter records to chosen stores (keeps stores+records consistent)
          records=[r for r in records if r["store_key"] in set(uniq)]

          # build stores objects from store_key itself (no guessing beyond derived split)
          stores=[]
          for sk in uniq:
              parts=sk.split(":",1)
              retailer=parts[0]
              store_id=parts[1] if len(parts)>1 else ""
              stores.append({
                  "retailer": retailer,
                  "store_id": store_id,
                  "store_key": sk,
                  "store_name": sk,   # derived, not external
                  "city": "",
                  "address": "",
                  "area": "",
                  "store_type": ""
              })

          # products upsert only for barcodes actually present in filtered records
          used_barcodes=sorted(set(r["barcode"] for r in records))
          products_upsert=[{"barcode": bc, "name": (barcode_to_name.get(bc) or "")} for bc in used_barcodes]

          os.makedirs("out", exist_ok=True)
          with open("out/products_upsert.json","w",encoding="utf-8") as f:
              json.dump(products_upsert,f,ensure_ascii=False)

          payload={
              "source":"collector_routeA_with_products_upsert",
              "generated_at": now_z(),
              "stores": stores,
              "records": records
          }
          with open("out/payload.json","w",encoding="utf-8") as f:
              json.dump(payload,f,ensure_ascii=False)

          with open("out/stats.txt","w",encoding="utf-8") as f:
              f.write(f"stores={len(stores)}\nrecords={len(records)}\nproducts_upsert={len(products_upsert)}\n")

          print(f"stores={len(stores)}, records={len(records)}, products_upsert={len(products_upsert)}")
          PY

      - name: Upsert products to Supabase (ensure barcode FK)
        if: ${{ inputs.run_mode == 'stores_prices' && inputs.send_to_make == 'true' }}
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_JWT: ${{ secrets.SUPABASE_SERVICE_ROLE_JWT }}
        run: |
          set -euo pipefail
          test -f out/products_upsert.json
          curl -sS -X POST "${SUPABASE_URL}/rest/v1/products?on_conflict=barcode" \
            -H "Content-Type: application/json" \
            -H "Prefer: resolution=merge-duplicates,return=minimal" \
            -H "apikey: ${SUPABASE_SERVICE_ROLE_JWT}" \
            -H "Authorization: Bearer ${SUPABASE_SERVICE_ROLE_JWT}" \
            --data-binary @out/products_upsert.json

      - name: POST payload to Make (ONE POST)
        if: ${{ inputs.run_mode == 'stores_prices' && inputs.send_to_make == 'true' }}
        env:
          MAKE_WEBHOOK_URL: ${{ secrets.MAKE_WEBHOOK_URL }}
          MAKE_APIKEY: ${{ secrets.MAKE_APIKEY }}
        run: |
          set -euo pipefail
          test -f out/payload.json
          python3 - <<'PY'
          import json
          p=json.load(open("out/payload.json","r",encoding="utf-8"))
          if len(p.get("stores") or []) < 1: raise SystemExit("ABORT: stores empty")
          if len(p.get("records") or []) < 2: raise SystemExit("ABORT: records<2")
          PY
          curl -sS -X POST "$MAKE_WEBHOOK_URL" \
            -H "Content-Type: application/json" \
            -H "x-make-apikey: $MAKE_APIKEY" \
            --data-binary @out/payload.json

      - name: Upload artifacts (out/)
        if: ${{ inputs.run_mode != 'inspect' }}
        uses: actions/upload-artifact@v4
        with:
          name: glutiwise-out
          path: out/
