name: GlutiWise Collector (STORE+PRICE hardcoded, Route A to satisfy store_key FK)

on:
  workflow_dispatch:
    inputs:
      run_mode:
        description: "inspect | seed_products | stores_prices"
        required: true
        default: "seed_products"
      send_to_make:
        description: "רק עבור stores_prices: לשלוח ל-Make (true/false)"
        required: true
        default: "false"
      limit_seed:
        description: "LIMIT להרצת seed (מומלץ 20)"
        required: true
        default: "20"
      limit_prices:
        description: "LIMIT להרצת מחירים (מומלץ 20 לבדיקה, 120 להרצה מלאה)"
        required: true
        default: "20"
      seed_limit:
        description: "כמה ברקודים להוציא ל-products_seed.csv (מומלץ 2000)"
        required: true
        default: "2000"
      max_records:
        description: "תקרת records ל-payload.json (מומלץ 3000)"
        required: true
        default: "3000"
      max_stores:
        description: "כמה סניפים לשלוח במקסימום (MVP=30)"
        required: true
        default: "30"

jobs:
  run:
    runs-on: ubuntu-latest
    steps:
      - name: Prepare folders
        run: |
          mkdir -p dumps out

      - name: Pull scraper image
        run: |
          docker pull erlichsefi/israeli-supermarket-scarpers:latest

      # =========================
      # INSPECT (no Make)
      # =========================
      - name: Inspect image (fast hints)
        if: ${{ inputs.run_mode == 'inspect' }}
        run: |
          set -euo pipefail
          docker run --rm --entrypoint sh erlichsefi/israeli-supermarket-scarpers:latest -lc '
            set -e
            echo "== HINTS (grep) =="
            grep -RIn --line-number --binary-files=without-match -E "ENABLED_FILE_TYPES|STORE_FILE|PRICE_FILE|PRICE_FULL_FILE|PROMO_FILE|FILE_TYPE" . 2>/dev/null | head -n 200 || true
            echo "== DONE =="
          '

      # =========================
      # DOWNLOAD (hardcoded, no discover)
      # =========================
      - name: Download STORE + PRICE files (hardcoded types)
        if: ${{ inputs.run_mode == 'seed_products' || inputs.run_mode == 'stores_prices' }}
        run: |
          set -euo pipefail

          ENABLED_FILE_TYPES="STORE_FILE,PRICE_FILE,PRICE_FULL_FILE"
          if [ "${{ inputs.run_mode }}" = "seed_products" ]; then
            LIMIT="${{ inputs.limit_seed }}"
          else
            LIMIT="${{ inputs.limit_prices }}"
          fi

          echo "ENABLED_FILE_TYPES=$ENABLED_FILE_TYPES"
          echo "LIMIT=$LIMIT"

          docker run --rm \
            -v "${{ github.workspace }}/dumps:/usr/src/app/dumps" \
            -e ENABLED_SCRAPERS="RAMI_LEVY,SHUFERSAL,YOHANANOF" \
            -e ENABLED_FILE_TYPES="$ENABLED_FILE_TYPES" \
            -e LIMIT="$LIMIT" \
            erlichsefi/israeli-supermarket-scarpers:latest

      # =========================
      # SEED: products_seed.csv (PRICE-only, no STORE dependency)
      # =========================
      - name: Build products_seed.csv (PRICE-only)
        if: ${{ inputs.run_mode == 'seed_products' }}
        env:
          SEED_LIMIT: ${{ inputs.seed_limit }}
        run: |
          set -euo pipefail
          python3 - <<'PY'
          import os, re, glob, gzip, zipfile
          import xml.etree.ElementTree as ET

          SEED_LIMIT=int(os.environ.get("SEED_LIMIT","2000"))

          def localname(tag): return tag.split("}")[-1] if "}" in tag else tag
          def norm(s): return re.sub(r"\s+"," ",(s or "").strip())

          def load_xml_roots(path):
              lp=path.lower()
              if lp.endswith(".zip"):
                  roots=[]
                  with zipfile.ZipFile(path,"r") as z:
                      for nm in z.namelist():
                          if nm.lower().endswith(".xml"):
                              roots.append(ET.fromstring(z.read(nm)))
                  return roots
              if lp.endswith(".xml.gz") or lp.endswith(".gz"):
                  with gzip.open(path,"rb") as f:
                      return [ET.fromstring(f.read())]
              return [ET.parse(path).getroot()]

          def iter_dump_paths():
              for p in glob.glob("dumps/**/*", recursive=True):
                  if os.path.isfile(p) and p.lower().endswith((".xml",".gz",".zip",".xml.gz")):
                      yield p

          BARCODE_KEYS = {"itemcode","barcode","gtin","ean","code","itemid","itemnumber"}
          NAME_KEYS = {"itemname","itemdescription","productname","description","name"}

          def extract_any(elem, keys):
              keys={k.lower() for k in keys}
              for el in elem.iter():
                  if localname(el.tag).lower() in keys and (el.text or "").strip():
                      return norm(el.text)
              for el in elem.iter():
                  for k,v in (el.attrib or {}).items():
                      kk=str(k).lower()
                      if any(x in kk for x in ["barcode","gtin","itemcode","ean","code"]):
                          vv=(v or "").strip()
                          if vv: return norm(vv)
              return ""

          seed={}
          stats={"files_seen":0,"roots_seen":0,"items_seen":0}

          for path in iter_dump_paths():
              base=os.path.basename(path).lower()
              if base.startswith("stores"):
                  continue
              stats["files_seen"] += 1
              try:
                  roots=load_xml_roots(path)
              except Exception:
                  continue
              for root in roots:
                  stats["roots_seen"] += 1
                  for node in root.iter():
                      if localname(node.tag).lower() not in {"item","product"}:
                          continue
                      stats["items_seen"] += 1
                      bc=extract_any(node, BARCODE_KEYS).strip()
                      if not bc:
                          continue
                      if bc not in seed and len(seed) < SEED_LIMIT:
                          nm=extract_any(node, NAME_KEYS).strip()
                          seed[bc]=nm
                      if len(seed) >= SEED_LIMIT:
                          break
                  if len(seed) >= SEED_LIMIT:
                      break
              if len(seed) >= SEED_LIMIT:
                  break

          os.makedirs("out", exist_ok=True)
          with open("out/products_seed.csv","w",encoding="utf-8") as f:
              f.write("barcode,name\n")
              for bc,nm in seed.items():
                  f.write(f"{bc},{(nm or '').replace(',', ' ')}\n")

          with open("out/seed_stats.txt","w",encoding="utf-8") as f:
              for k,v in stats.items():
                  f.write(f"{k}: {v}\n")
              f.write(f"seed_unique: {len(seed)}\n")

          print(f"seed_unique={len(seed)}")
          PY

      # =========================
      # STORES_PRICES: build stores+records payload (Route A) to satisfy store_key FK
      # =========================
      - name: Build payload (stores + records, bounded, Route A)
        if: ${{ inputs.run_mode == 'stores_prices' }}
        env:
          SEED_LIMIT: ${{ inputs.seed_limit }}
          MAX_RECORDS: ${{ inputs.max_records }}
          MAX_STORES: ${{ inputs.max_stores }}
        run: |
          set -euo pipefail
          python3 - <<'PY'
          import os, re, json, glob, gzip, zipfile
          import xml.etree.ElementTree as ET
          from datetime import datetime, timezone

          SEED_LIMIT = int(os.environ.get("SEED_LIMIT","2000"))
          MAX_RECORDS_TOTAL = int(os.environ.get("MAX_RECORDS","3000"))
          MAX_STORES_TOTAL = int(os.environ.get("MAX_STORES","30"))

          def now_z():
              return datetime.now(timezone.utc).replace(microsecond=0).isoformat().replace("+00:00","Z")
          def localname(tag): return tag.split("}")[-1] if "}" in tag else tag
          def norm(s): return re.sub(r"\s+"," ",(s or "").strip())

          def canon_store_id(s: str) -> str:
              s=(s or "").strip()
              if re.fullmatch(r"\d+", s or ""):
                  try:
                      return str(int(s))
                  except Exception:
                      return s
              return s

          def load_xml_roots(path):
              lp=path.lower()
              if lp.endswith(".zip"):
                  roots=[]
                  with zipfile.ZipFile(path,"r") as z:
                      for nm in z.namelist():
                          if nm.lower().endswith(".xml"):
                              roots.append(ET.fromstring(z.read(nm)))
                  return roots
              if lp.endswith(".xml.gz") or lp.endswith(".gz"):
                  with gzip.open(path,"rb") as f:
                      return [ET.fromstring(f.read())]
              return [ET.parse(path).getroot()]

          def iter_dump_paths():
              for p in glob.glob("dumps/**/*", recursive=True):
                  if os.path.isfile(p) and p.lower().endswith((".xml",".gz",".zip",".xml.gz")):
                      yield p

          def extract_any(elem, keys):
              keys={k.lower() for k in keys}
              for el in elem.iter():
                  if localname(el.tag).lower() in keys and (el.text or "").strip():
                      return norm(el.text)
              return ""

          CHAINID_TO_RETAILER={"7290027600007":"ramilevy","7290058140886":"shufersal"}
          def retailer_from(chain_id, chain_name):
              if (chain_id or "") in CHAINID_TO_RETAILER: return CHAINID_TO_RETAILER[chain_id]
              cn=chain_name or ""
              if "שופרסל" in cn: return "shufersal"
              if "רמי" in cn: return "ramilevy"
              if "יוחננוף" in cn or "YOHANANOF" in cn.upper(): return "yohananof"
              return None

          def city_from_shuf_name(name: str) -> str:
              n=norm(name)
              if not n:
                  return ""
              parts=n.split(" ")
              if len(parts)>=2:
                  last2=" ".join(parts[-2:])
                  if re.search(r"[א-ת]", last2):
                      return last2
              last1=parts[-1]
              if re.search(r"[א-ת]", last1):
                  return last1
              return ""

          # ---------- 1) Parse STORE files into dict store_key -> store object ----------
          store_dict = {}
          store_files_seen = 0
          stores_parsed = 0

          for path in iter_dump_paths():
              base=os.path.basename(path).lower()
              # store files usually start with "stores", but be robust: try any xml that has <Store> nodes
              try:
                  roots=load_xml_roots(path)
              except Exception:
                  continue

              for root in roots:
                  # quick check for store-like structure
                  has_store = any(localname(el.tag).lower()=="store" for el in root.iter())
                  if not has_store:
                      continue

                  store_files_seen += 1
                  chain_id = extract_any(root, {"chainid"})
                  chain_name = extract_any(root, {"chainname"})
                  retailer = retailer_from(chain_id, chain_name)
                  if not retailer:
                      continue

                  for el in root.iter():
                      if localname(el.tag).lower() != "store":
                          continue
                      store_id = canon_store_id(extract_any(el, {"storeid"}))
                      if not store_id:
                          continue
                      name = extract_any(el, {"storename"}) or ""
                      address = extract_any(el, {"address"}) or ""
                      if address.lower() == "unknown":
                          address = ""
                      city = extract_any(el, {"city"}) or ""
                      if (not city) or city.lower() == "unknown" or re.fullmatch(r"\d+", city or ""):
                          city = ""
                      if retailer == "shufersal" and not city:
                          city = city_from_shuf_name(name)

                      store_key = f"{retailer}:{store_id}"

                      obj = {
                          "retailer": retailer,
                          "store_id": store_id,
                          "store_key": store_key,
                          "store_name": name,
                          "city": city,
                          "address": address,
                          "area": "",
                          "store_type": ""
                      }
                      store_dict[store_key] = obj
                      stores_parsed += 1

          if not store_dict:
              raise SystemExit("No STORE records parsed from downloaded files (unexpected).")

          # ---------- 2) Parse PRICE files: seed barcodes + collect available store_keys ----------
          BARCODE_KEYS={"itemcode","barcode","gtin","ean","code","itemid","itemnumber"}
          NAME_KEYS={"itemname","itemdescription","productname","description","name"}
          PRICE_KEYS={"itemprice","price","unitprice","saleprice","priceafterdiscount","priceinclvat"}

          def safe_float(x):
              x=(x or "").strip().replace(",", ".")
              try:
                  v=float(x)
                  return v if v>=0 else None
              except Exception:
                  return None

          def extract_barcode(node):
              bc = extract_any(node, BARCODE_KEYS).strip()
              if bc:
                  return bc
              # attributes fallback for barcode-like
              for el in node.iter():
                  for k,v in (el.attrib or {}).items():
                      kk=str(k).lower()
                      if any(t in kk for t in ["barcode","gtin","itemcode","ean","code"]):
                          vv=(v or "").strip()
                          if vv:
                              return norm(vv)
              return ""

          def extract_name(node):
              nm = extract_any(node, NAME_KEYS).strip()
              return nm

          seed_map = {}         # barcode -> name
          price_store_keys = [] # store_keys that appear in downloaded price files
          price_files_seen = 0
          price_candidates = 0
          items_scanned = 0

          for path in iter_dump_paths():
              base=os.path.basename(path).lower()
              if base.startswith("stores"):
                  continue
              try:
                  roots=load_xml_roots(path)
              except Exception:
                  continue

              for root in roots:
                  chain_id=extract_any(root, {"chainid"})
                  chain_name=extract_any(root, {"chainname"})
                  store_id=canon_store_id(extract_any(root, {"storeid"}))
                  retailer=retailer_from(chain_id, chain_name)
                  if not retailer or not store_id:
                      continue

                  price_files_seen += 1
                  store_key = f"{retailer}:{store_id}"
                  price_store_keys.append(store_key)

                  # scan items for seed
                  item_nodes = [n for n in root.iter() if localname(n.tag).lower() in {"item","product"}]
                  if not item_nodes:
                      continue
                  price_candidates += 1

                  for node in item_nodes:
                      items_scanned += 1
                      bc = extract_barcode(node)
                      if not bc:
                          continue
                      if bc not in seed_map and len(seed_map) < SEED_LIMIT:
                          seed_map[bc] = extract_name(node)
                      if len(seed_map) >= SEED_LIMIT:
                          break
                  # keep going to collect store_keys; seed can stop early safely

          # choose stores based on stores that actually appear in the downloaded price files
          seen = set()
          selected_store_keys = []
          for sk in price_store_keys:
              if sk in store_dict and sk not in seen:
                  seen.add(sk)
                  selected_store_keys.append(sk)
              if len(selected_store_keys) >= MAX_STORES_TOTAL:
                  break

          # fallback: if for some reason none matched, pick any from store_dict
          if not selected_store_keys:
              selected_store_keys = list(store_dict.keys())[:MAX_STORES_TOTAL]

          selected_stores = [store_dict[sk] for sk in selected_store_keys]

          # ---------- 3) Build records only for selected stores + seed barcodes, bounded + dedupe ----------
          dedup = {}
          for path in iter_dump_paths():
              base=os.path.basename(path).lower()
              if base.startswith("stores"):
                  continue
              try:
                  roots=load_xml_roots(path)
              except Exception:
                  continue

              for root in roots:
                  chain_id=extract_any(root, {"chainid"})
                  chain_name=extract_any(root, {"chainname"})
                  store_id=canon_store_id(extract_any(root, {"storeid"}))
                  retailer=retailer_from(chain_id, chain_name)
                  if not retailer or not store_id:
                      continue

                  store_key=f"{retailer}:{store_id}"
                  if store_key not in seen:
                      continue

                  updated_at = now_z()
                  for node in root.iter():
                      if localname(node.tag).lower() not in {"item","product"}:
                          continue
                      bc = extract_barcode(node)
                      if not bc or bc not in seed_map:
                          continue
                      pv = safe_float(extract_any(node, PRICE_KEYS))
                      if pv is None:
                          continue
                      price_key=f"{bc}:{store_key}"
                      dedup[price_key]={
                          "price_key": price_key,
                          "barcode": bc,
                          "store_key": store_key,
                          "price": pv,
                          "updated_at": updated_at
                      }
                      if len(dedup) >= MAX_RECORDS_TOTAL:
                          break
                  if len(dedup) >= MAX_RECORDS_TOTAL:
                      break
              if len(dedup) >= MAX_RECORDS_TOTAL:
                  break

          records = list(dedup.values())

          os.makedirs("out", exist_ok=True)

          # write products_seed.csv for transparency (matches seed_map used)
          with open("out/products_seed.csv","w",encoding="utf-8") as f:
              f.write("barcode,name\n")
              for bc,nm in seed_map.items():
                  f.write(f"{bc},{(nm or '').replace(',', ' ')}\n")

          payload = {
              "source": "collector_stores_prices_routeA_bounded",
              "generated_at": now_z(),
              "stores": selected_stores,
              "records": records
          }
          with open("out/payload.json","w",encoding="utf-8") as f:
              json.dump(payload,f,ensure_ascii=False)

          stats = {
              "store_files_seen": store_files_seen,
              "stores_parsed_total": stores_parsed,
              "store_dict_unique": len(store_dict),
              "price_files_seen": price_files_seen,
              "price_candidates": price_candidates,
              "items_scanned": items_scanned,
              "seed_unique": len(seed_map),
              "selected_stores": len(selected_store_keys),
              "records_after_dedupe": len(records)
          }
          with open("out/price_stats.txt","w",encoding="utf-8") as f:
              for k,v in stats.items():
                  f.write(f"{k}: {v}\n")

          print(json.dumps(stats, ensure_ascii=False))
          PY

      - name: Upload artifacts (out/)
        if: ${{ inputs.run_mode != 'inspect' }}
        uses: actions/upload-artifact@v4
        with:
          name: glutiwise-out
          path: out/

      # =========================
      # POST TO MAKE (ONE POST)
      # =========================
      - name: POST out/payload.json to Make (ONE POST)
        if: ${{ inputs.run_mode == 'stores_prices' && inputs.send_to_make == 'true' }}
        env:
          MAKE_WEBHOOK_URL: ${{ secrets.MAKE_WEBHOOK_URL }}
          MAKE_APIKEY: ${{ secrets.MAKE_APIKEY }}
        run: |
          set -euo pipefail
          test -f out/payload.json

          python3 - <<'PY'
          import json
          p=json.load(open("out/payload.json","r",encoding="utf-8"))
          n=len(p.get("records") or [])
          s=len(p.get("stores") or [])
          print(f"stores={s}, records={n}")
          if s < 1:
              raise SystemExit("ABORT: stores<1 (would not route to A reliably)")
          if n < 2:
              raise SystemExit("ABORT: records<2 (not sending to Make)")
          PY

          curl -sS -X POST "$MAKE_WEBHOOK_URL" \
            -H "Content-Type: application/json" \
            -H "x-make-apikey: $MAKE_APIKEY" \
            --data-binary @out/payload.json
